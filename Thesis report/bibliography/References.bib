@misc{_3d_2013,
author = {Type, Document and Date, Publish},
booktitle = {www.ni.com},
month = {aug},
pages = {1--5},
title = {{3D Imaging with NI LabVIEW}},
url = {http://www.ni.com/white-paper/14103/en/},
urldate = {2015-12-28},
year = {2012}
}
@article{Scharstein2001,
abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web},
author = {Scharstein, Daniel and Szeliski, Richard},
doi = {10.1023/A:1014573219977},
file = {:home/raam/Thesis/References/Middlebury1.pdf:pdf},
isbn = {0-7695-1327-1},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Evaluation of performance,Stereo correspondence software,Stereo matching survey},
number = {1-3},
pages = {7--42},
pmid = {350},
title = {{A taxonomy and evaluation of dense two-frame stereo correspondence algorithms}},
volume = {47},
year = {2002}
}
@misc{harris_about,
author = {Harris, Mark},
booktitle = {GPGPU},
title = {{About GPGPU.org}},
url = {http://gpgpu.org/about{\#}disqus{\_}thread},
urldate = {2015-12-23}
}
@article{Xu2014,
author = {Xu, Tian and Cockshott, Paul and Oehler, Susanne},
doi = {10.1109/HPCC.2014.22},
file = {:home/raam/Thesis/References/AccelerationStereoMulticoreCPUandGPU.pdf:pdf},
isbn = {9781479961238},
journal = {Proceedings - 16th IEEE International Conference on High Performance Computing and Communications, HPCC 2014, 11th IEEE International Conference on Embedded Software and Systems, ICESS 2014 and 6th International Symposium on Cyberspace Safety and Security},
keywords = {Acceleration,Dense-correspondences,Multi-core CPU,Robotic vision,Stereo matching},
pages = {108--115},
title = {{Acceleration of stereo-matching on multi-core CPU and GPU}},
year = {2014}
}
@article{pinhas_ben-tzvi_embedded_2010,
abstract = {Stereo vision systems have recently become an essential part for most autonomous mobile robots. There are several commercially available stereo vision products, which have been used for autonomous functions in mobile robot platforms. However, most of them are not suitable for compact sized robots. This paper presents an embedded stereo vision system that provides flexible baseline for robots of compact size. In terms of hardware, it provides baseline flexibility, and can be easily fitted into any robot. In terms of software, a feature based stereo vision algorithm is proposed to improve the real-time performance of the stereo vision system. The proposed featured-based method is evaluated by comparing it with the area-based method using standard test images. The results show that the computational time is significantly reduced (reduced by 60{\%} in a relatively complex image). The proposed method is also implemented in real world environments in order to test its effectiveness.},
author = {Ben-Tzvi, Pinhas and Xu, Xin},
doi = {10.1109/ROSE.2010.5675303},
file = {:home/raam/Thesis/References/Embedded SV sys for autonomous robots.pdf:pdf},
isbn = {9781424471461},
issn = {978-1-4244-7147-8},
journal = {ROSE 2010 - 2010 IEEE International Workshop on Robotic and Sensors Environments, Proceedings},
keywords = {Correspondence,Embedded stereo vision system,Feature extraction},
pages = {176--181},
title = {{An embedded feature-based stereo vision system for autonomous mobile robots}},
year = {2010}
}
@techreport{GyorgyTamasBiroKaroly-Agoston2015,
abstract = {Stereo vision, the knowledge of deep information in a scene, has great importance in the field of machine vision, robotics and image analysis. In this article an analysis of existing stereo vision matching methods is presented. The presented algorithms are discussed in terms of speed, accuracy, disparity range and time consumption. Implementations of stereo-matching algorithms in hardware are also discussed in details.},
author = {{Gy{\"{o}}rgy Tam{\'{a}}s, B{\'{i}}r{\'{o}} K{\'{a}}roly-{\'{A}}goston}, Szab{\'{o}} Tam{\'{a}}s},
file = {:home/raam/Thesis/References/C3{\_}3{\_}Gyorgy{\_}Tamas.pdf:pdf},
institution = {Technical University of Cluj-Napoca},
title = {{An experimental comparison of stereo vision algorithms using middlebury dataset}},
year = {2015}
}
@misc{Rege,
author = {Rege, Ashu},
publisher = {NVIDIA},
title = {{An Introduction to Modern GPU Architecture}},
url = {ftp://download.nvidia.com/developer/cuda/seminar/TDCI{\_}Arch.pdf}
}
@article{Cabezas2012,
abstract = {— The percentage of Bad Matched widely used for evaluating disparity maps. It of differences between estimated disparity v truth values that exceed a threshold. A small the same way that a large one by comput Moreover, the BMP ignores the inverse relat and disparity. Although, the percentages of BM disparity maps may produce different 3D re Mean Relative Error (MRE) is calculated as a of error magnitudes against true disparity valu inverse relation between depth and disparity. H MRE, every deviation from ground-truth is error, regardless the application domain for w map was estimated. In this paper, an error m evaluating disparity maps is introduced. The in combines the advantages of the BMP and the user to declare what an estimation error is – u and considers both, the error magnitude and t between depth and disparity. The proposed m BMPRE and it determines estimation errors in way by the community and, at the same tim information, but flexibility, about the impact the context of a 3D recovery process. Compar experimental evaluation show that the BMP evaluation of disparity maps, which impacts comparison of stereo correspondence algorithm Stereo vision; quantitative evaluation; error maps.},
author = {Cabezas, Ivan and Padilla, Victor and Trujillo, Maria},
doi = {10.1109/ICoSP.2012.6491759},
file = {:home/raam/Thesis/References/BMPRE.pdf:pdf},
isbn = {9781467321945},
issn = {21544824},
journal = {International Conference on Signal Processing Proceedings, ICSP},
keywords = {Stereo vision,disparity maps,error measure,quantitative evaluation},
pages = {1051--1055},
title = {{BMPRE: An Error measure for evaluating disparity maps}},
volume = {2},
year = {2012}
}
@article{Kalarot2010,
abstract = {Real-time stereo vision systems have many applications - from autonomous navigation for vehicles through surveillance to materials handling. Accurate scene interpretation depends on an ability to process high resolution images in real-time, but, although the calculations for stereo matching are basically simple, a practical system needs to evaluate at least 109 disparities every second - beyond the capability of a single processor. Stereo correspondence algorithms have high degrees of inherent parallelism and are thus good candidates for parallel implementations. In this paper, we compare the performance obtainable with an FPGA and a GPU to understand the trade-off between the flexibility but relatively low speed of an FPGA and the high speed and fixed architecture of the GPU. Our comparison highlights the relative strengths and limitations of the two systems. Our experiments show that, for a range of image sizes, the GPU manages 2 {\&}{\#}x00D7; 10{\textless}sup{\textgreater}9{\textless}/sup{\textgreater} disparities per second, compared with 2.6 {\&}{\#}x00D7; 10{\textless}sup{\textgreater}9{\textless}/sup{\textgreater} disparities per second for an FPGA.},
author = {Kalarot, Ratheesh and Morris, John},
doi = {10.1109/CVPRW.2010.5543743},
file = {:home/raam/Thesis/References/GPUvsFPGA.pdf:pdf},
isbn = {9781424470297},
issn = {10459219},
journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010},
pages = {9--15},
title = {{Comparison of FPGA and GPU implementations of real-time stereo vision}},
year = {2010}
}
@book{Aho2006,
abstract = {This book provides the foundation for understanding the theory and pracitce of compilers. Revised and updated, it reflects the current state of compilation. Every chapter has been completely revised to reflect developments in software engineering, programming languages, and computer architecture that have occurred since 1986, when the last edition published. The authors, recognizing that few readers will ever go on to construct a compiler, retain their focus on the broader set of problems faced in software design and software development. Computer scientists, developers, and aspiring students that want to learn how to build, maintain, and execute a compiler for a major programming language.},
author = {Aho, Alfred V and Lam, Monica S and Sethi, Ravi and Ullman, Jeffrey D},
booktitle = {Reading MA},
doi = {0321486813},
file = {:home/raam/Thesis/References/ALSUdragonbook.pdf:pdf},
isbn = {0321486811},
number = {0},
pages = {1000},
publisher = {Pearson Addison Wesley},
title = {{Compilers: Principles, Techniques, and Tools (2nd Edition)}},
url = {http://www.amazon.com/Compilers-Principles-Techniques-Tools-2nd/dp/0321486811},
year = {2006}
}
@article{Choi2013,
author = {Choi, Young Kyu and Park, In Kyu},
doi = {10.1109/CVPRW.2013.97},
file = {:home/raam/Thesis/References/GraphCutGPU.pdf:pdf},
isbn = {9780769549903},
issn = {21607508},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
pages = {642--648},
title = {{Efficient gpu-based graph cuts for stereo matching}},
year = {2013}
}
@book{Souli2007,
abstract = {This tutorial is for those people who want to learn programming in C++ and do not necessarily have any previous knowledge of other programming languages. Of course any knowledge of other programming languages or any general computer skill can be useful to better understand this tutorial, although it is not essential.},
author = {Ramaprasad, Arkalgud and S{\'{a}}nchez-ortiz, Aurora and Syn, Thant},
booktitle = {cplusplus.com},
doi = {10.1007/978-3-319-22479-4},
file = {:home/raam/Thesis/References/C++tutorial.pdf:pdf},
isbn = {978-3-319-22478-7},
issn = {0937-6429},
keywords = {egovernment,gap analysis,ontology,roadmap},
pages = {258--269},
pmid = {14317784},
publisher = {cplusplus.com},
title = {{Electronic Government}},
url = {http://link.springer.com/10.1007/978-3-319-22479-4},
volume = {9248},
year = {2015}
}
@misc{derek_hoiem_epipolar_2011,
address = {University of Illinois},
author = {Geometry, A Epipolar},
month = {apr},
number = {part 1},
pages = {1--7},
title = {{Epipolar Geometry and Stereo ( 1 )}},
url = {https://courses.engr.illinois.edu/cs543/sp2011/lectures/Lecture 23 - Epipolar Geometry and Stereo - Vision{\_}Spring2011.pdf},
volume = {2},
year = {2005}
}
@article{young_ki_baik_fast_2006,
abstract = {In this paper, we propose a census transform-based fast stereo algorithm. Most conventional fast stereo algorithms are based on SAD (Sum of Absolute Difference) or NC (Normalized Correlation). However, SAD is often sensitive to noise or illumination changes. Image matching by census transform is known to be robust to radiometric distortion, since the differences in gain and bias between two images will not affect the ordering of pixels within a window. Thus, in this paper, we develop a fast and accurate census transform-based stereo algorithm using the moving window and parallel processing techniques. The resulting system computes 32 disparity of 320 by 240 images at 34 frames per second for the window size of 5x5.},
author = {Baik, Young Ki and Jo, Jung Ho and Lee, Kyoung Mu},
file = {:home/raam/Thesis/References/Fast CT.pdf:pdf},
journal = {Word Journal Of The International Linguistic Association},
pages = {2--3},
title = {{Fast Census Transform-based Stereo Algorithm using SSE2}},
volume = {2-3},
year = {2006}
}
@phdthesis{Rosli2014,
abstract = {Rapid development of the Field Programmable Gate Array (FPGA) offers an alternative way to provide acceleration for computationally intensive tasks such as digital signal and image processing. Its ability to perform parallel processing shows the potential in imple- menting a high speed vision system. Out of numerous applications of computer vision, this thesis focuses on the hardware implementation of one that is commercially known as Automatic Number Plate Recognition (ANPR). It is a modern CCTV-based surveillance method that has the ability to locate and recognize vehicle registration number. Mor- phological operations and Optical Character Recognition (OCR) algorithms have been implemented on a Xilinx Zynq-7000 All-Programmable SoC to realize the functions of an ANPR system. Test results have shown that the designed and implemented processing pipeline that consumed 63 {\%} of the logic resources is capable of delivering the results with relatively low error rate. Most importantly, the computation time satisfies the real-time requirement for many ANPR applications.},
author = {Rosli, Farid},
file = {:home/raam/Thesis/References/template.pdf:pdf},
keywords = {icle},
school = {TU Berlin},
title = {{FPGA Implementation of License Plate Detection and Recognition}},
year = {2014}
}
@article{Scharstein2003,
abstract = {Progress in stereo algorithm performance is quickly outpacing the ability of existing stereo data sets to discriminate among the best-performing algorithms, motivating the need for more challenging scenes with accurate ground truth information. This paper describes a method for acquiring high-complexity stereo image pairs with pixel-accurate correspondence information using structured light. Unlike traditional range-sensing approaches, our method does not require the calibration of the light sources and yields registered disparity maps between all pairs of cameras and illumination projectors. We present new stereo data sets acquired with our method and demonstrate their suitability for stereo algorithm evaluation. Our results are available at http://www.middlebury.edu/stereo/.},
author = {Scharstein, D and Szeliski, R},
doi = {10.1109/CVPR.2003.1211354},
file = {:home/raam/Thesis/References/High-Accuracy{\_}Stereo{\_}Depth{\_}Maps{\_}Using{\_}Structured{\_}Light.pdf:pdf},
isbn = {0-7695-1900-8},
issn = {1063-6919},
journal = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on},
keywords = {cameras,computer vision,image texture,stereo image processing},
number = {June},
pages = {I--195 -- I--202},
title = {{High-accuracy stereo depth maps using structured light}},
volume = {1},
year = {2003}
}
@misc{olea_introduction_2015,
author = {Olea, Luis and Martinez, Ioseph},
file = {:home/raam/Thesis/References/Introduction to embedded graphics freescale.pdf:pdf},
publisher = {Freescale Semiconductor},
title = {{Introduction to Embedded Graphics with Freescale Devices}},
year = {2015}
}
@article{Hamzah2015,
author = {Hamzah, Rostam Affendi and Ibrahim, Haidi},
doi = {10.1155/2016/8742920},
file = {:home/raam/Thesis/References/Literature survey on stereovision.pdf:pdf},
issn = {1687-725X},
journal = {Journal of sensors, Hindawi Publishing Corporation},
title = {{Literature Survey on Stereo Vision Disparity Map Algorithms}},
volume = {2016},
year = {2015}
}
@misc{threadcpp,
author = {Howard, David M},
number = {October},
title = {{Multithreading in}},
url = {https://www.tutorialcup.com/cplusplus/multithreading.htm},
urldate = {2016-02-29},
year = {1997}
}
@misc{_nema|s,
title = {{Nema-S, GPGPU}},
url = {http://www.think-silicon.com/product{\_}Nema{\_}GPGPU.php},
urldate = {2015-12-28}
}
@article{_new_2014,
journal = {gpgpu.org},
title = {{New Embedded GPU Platform for General-Purpose Computing Delivers the Highest Performance per Energy or Area}},
url = {http://gpgpu.org/2014/03/05/new-embedded-gpu-platform-for-general-purpose-computing-delivers-the-highest-performance-per-energy-or-area},
urldate = {2015-10-12},
year = {2014}
}
@misc{gpu2008,
booktitle = {IXBT LABS},
title = {{Non-graphic computing with graphics processors.}},
url = {http://ixbtlabs.com/articles3/video/cuda-1-p1.html},
urldate = {2016-05-05},
year = {2008}
}
@article{Zabih1994,
abstract = {We propose a new approach to the correspondence problem that makes use of non-parametric local transforms as the basis for correlation. Non-parametric local transforms rely on the relative ordering of local intensity values, and not on the intensity values themselves. Correlation using such transforms can tolerate a signi cant number of outliers. This can result in improved performance near object boundaries when compared with conventional methods such as normalized correlation. We introduce two non-parametric local transforms: the rank transform, which measures local intensity, and the census transform, which summarizes local image structure. We describe some properties of these transforms, and demonstrate their utility on both synthetic and real data.},
author = {Zabih, Ramin and Woodfill, John},
doi = {10.1007/BFb0028345},
file = {:home/raam/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zabih, Woodfill - 1994 - Non-parametric Local Transforms for Computing Visual Correspondence.pdf:pdf},
isbn = {978-3-540-48400-4},
issn = {19461488},
journal = {In Proceedings of European Conference on Computer Vision},
pages = {151--158},
title = {{Non-parametric Local Transforms for Computing Visual Correspondence}},
year = {1994}
}
@misc{Collange2015,
address = {Rennes},
author = {Collange, Sylvain},
title = {{Parallel programming: Introduction to GPU architecture}},
url = {http://www.irisa.fr/alf/downloads/collange/cours/ppar2015/ppar2015{\_}gpu{\_}1.pdf},
year = {2015}
}
@misc{Apostolou2015,
author = {Apostolou, Panagiotis},
file = {:home/raam/Thesis/hevcdec-nema/README.TSi:TSi},
publisher = {Think Silicon Ltd.},
title = {{Programming the Nema GPU}},
year = {2015}
}
@article{Martull2012,
author = {Martull, Sarah and Peris, Martin and Fukui, Kazuhiro},
file = {:home/raam/Thesis/References/Realistic{\_}CG{\_}Stereo{\_}Image{\_}Dataset{\_}with{\_}Ground{\_}Truth{\_}Disparity{\_}Maps:},
journal = {ICPR2012 workshop TrakMark2012},
title = {{Realistic CG stereo image dataset with ground truth disparity maps}},
year = {2012}
}
@misc{Colubri,
author = {Colubri, Andres},
booktitle = {processing.org},
title = {{Shaders}},
url = {https://processing.org/tutorials/pshader/},
urldate = {2016-05-05}
}
@article{Peris2012,
author = {Peris, Martin and Maki, A and Martull, S},
file = {:home/raam/Thesis/References/Towards{\_}a{\_}Simulation{\_}Driven{\_}Stereo{\_}Vision{\_}System.pdf:pdf},
isbn = {9784990644116},
issn = {1051-4651},
journal = {21st International Conference on Pattern Recognition},
pages = {1038--1042},
title = {{Towards a simulation driven stereo vision system}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6460313},
year = {2012}
}
@misc{Siewert2009,
author = {Siewert, Sam},
booktitle = {Intel developer zone},
title = {{Using Intel{\textregistered} Streaming SIMD Extensions and Intel{\textregistered} Integrated Performance Primitives to Accelerate Algorithms}},
url = {https://software.intel.com/en-us/articles/using-intel-streaming-simd-extensions-and-intel-integrated-performance-primitives-to-accelerate-algorithms},
urldate = {2015-10-01},
year = {2009}
}
@article{Geiger2013,
abstract = {We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10–Hz using a variety of sensor modalities such as high-resolution color and grayscale stereo cameras, a Velodyne 3D laser scanner and a high-precision GPS/IMU inertial navigation system. The scenarios are diverse, capturing real-world traffic situations, and range from freeways over rural areas to inner-city scenes with many static and dynamic objects. Our data is calibrated, synchronized and timestamped, and we provide the rectified and raw image sequences. Our dataset also contains object labels in the form of 3D tracklets, and we provide online benchmarks for stereo, optical flow, object detection and other tasks. This paper describes our recording platform, the data format and the utilities that we provide.},
author = {Geiger, Andreas and Lenz, Philip and Stiller, Cristoph and Urtasun, Raquel},
doi = {10.1177/0278364913491297},
file = {:home/raam/Thesis/References/Vision{\_}meets{\_}Robotics$\backslash$:{\_}The{\_}KITTI{\_}Dataset.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {GPS,KITTI,SLAM,autonomous driving,benchmarks,cameras,computer vision,dataset,field robotics,laser,mobile robotics,object detection,optical flow,stereo,tracking},
number = {11},
pages = {1231--1237},
title = {{Vision meets robotics: The KITTI dataset}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364913491297},
volume = {32},
year = {2013}
}
@article{Kolmogorov2004,
abstract = {In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.},
author = {Kolmogorov, Vladimir and Zabih, Ramin},
doi = {10.1109/TPAMI.2004.1262177},
file = {:home/raam/Thesis/References/GraphCutEnergy.pdf:pdf},
isbn = {3-540-43746-0},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Energy minimization,Graph algorithms,Markov Random Fields,Maximum flow,Minimum cut,Optimization},
number = {2},
pages = {147--159},
pmid = {15376891},
title = {{What Energy Functions Can Be Minimized via Graph Cuts?}},
volume = {26},
year = {2004}
}
@article{Mota2014,
author = {Mota, Vasco and Falcao, Gabriel and Antunes, Mario and Barreto, Joao and Nunes, Urbano},
doi = {10.1109/ICASSP.2014.6855062},
file = {:home/raam/Thesis/References/SymStereo.pdf:pdf},
isbn = {9781479928927},
issn = {15206149},
journal = {IEEE International Conference on Acoustics, Speech and Signal Processing},
pages = {7520--7524},
title = {{Using the GPU for fast symmetry-based dense stereo matching in high resolution images}},
year = {2014}
}
